import os
import json
import autogen
from dotenv import load_dotenv
from typing import Dict, Any
load_dotenv()

from skills_for_all_agent.skill_tool import skill_tool, DEFAULT_SKILLS_ROOT


# =========================================================
# 1. 统一 Tool 执行函数（对齐 LlamaIndex run_skill_tool）
# =========================================================

def run_skill_tool(payload: Dict[str, Any]) -> str:
    """
    payload:
    {
        "action": "<action_name>",
        "arg": "<string argument>"
    }
    """
    print("\n" + "=" * 80)
    print("[TOOL CALL] skill_tool")
    print("[INPUT PAYLOAD]")
    print(json.dumps(payload, ensure_ascii=False, indent=2))

    result = skill_tool(payload)

    print("[RAW RESULT]")
    print(json.dumps(result, ensure_ascii=False, indent=2))
    print("=" * 80 + "\n")

    return json.dumps(result, ensure_ascii=False, indent=2)


# =========================================================
# 2. 给 LLM 的 Tool schema（只暴露一个 skill_tool）
# =========================================================

functions = [
    {
        "name": "skill_tool",
        "description": (
             f"""
Unified skill tool. If you are not sure, you can first use the "list_metadata" function of this tool to search for available skills. Then, determine which skill might be the most useful. After that, try to read the SKILL.md file under this skill path to get more detailed information. Finally, based on the content of this file, decide whether to read the documentation in other paths or directly execute the relevant script.

Input format:
{{
  "action": "<action_name>",
  "arg": "<string argument>"
}}

Actions:
- list_metadata: arg = skills root directory (default: {DEFAULT_SKILLS_ROOT})
- read_file:     arg = file path
- run_command:   arg = full command string
"""
        ),
    "parameters": {
            "type": "object",
            "properties": {
                "payload": {
                    "type": "object",
                    "properties": {
                        "action": {
                            "type": "string",
                            "description": "Action name"
                        },
                        "arg": {
                            "type": "string",
                            "description": "Argument for the action"
                        }
                    },
                    "required": ["action", "arg"]
                }
            },
            "required": ["payload"]
        }
    }
]

# =========================================================
# 3. AssistantAgent（只负责推理）
# =========================================================

assistant = autogen.AssistantAgent(
    name="assistant",
    system_message=(
        "You are a helpful assistant."
        "When the task is completed, respond with EXACTLY the word:\n"
        "   TERMINATE\n"
    ),
    llm_config={
        "model": os.getenv("MODEL"),  
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
        "temperature": 0,
        "functions": functions,
    },
)

# =========================================================
# 4. UserProxyAgent（只执行工具）
# =========================================================

user = autogen.UserProxyAgent(
    name="user",
    human_input_mode="NEVER",
    code_execution_config={"use_docker": False},
    max_consecutive_auto_reply=None,  # ✅ 关键：执行一次就停
    is_termination_msg=lambda msg: (
        isinstance(msg, dict)
        and msg.get("content", "").strip() == "TERMINATE"
    ),
)

user.register_function(
    function_map={
        "skill_tool": run_skill_tool
    }
)

# =========================================================
# 5. 启动任务
# =========================================================

user.initiate_chat(
    assistant,
    message="我想将 #include <stdio.h>\n\nint main() {\n    puts(\"Generated by agent\");\n    return 0;\n}\n  这段代码转换为ast" # "我想非常深入地了解 AST" #"我想将 #include <stdio.h>\n\nint main() {\n    puts(\"Generated by agent\");\n    return 0;\n}\n  这段代码转换为ast"
)
