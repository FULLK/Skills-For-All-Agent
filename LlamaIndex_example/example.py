from dotenv import load_dotenv
load_dotenv()

import os
import json
import asyncio
from typing import Dict, Any

from llama_index.llms.openai_like import OpenAILike
from llama_index.core.agent import ReActAgent
from llama_index.core.tools import FunctionTool

from skills_for_all_agent.skill_tool import skill_tool, DEFAULT_SKILLS_ROOT

import logging

# logging.basicConfig(
#     level=logging.DEBUG,
#     format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
# )



# =========================================================
# 1. Tool 执行函数
# =========================================================

def run_skill_tool(payload: Dict[str, Any]) -> str:
    """
    payload:
    {
        "action": "<action_name>",
        "arg": "<string argument>"
    }
    """
    print("\n" + "=" * 80)
    print("[TOOL CALL] skill_tool")
    print("[INPUT PAYLOAD]")
    print(json.dumps(payload, ensure_ascii=False, indent=2))

    result = skill_tool(payload)

    print("[RAW RESULT]")
    print(json.dumps(result, ensure_ascii=False, indent=2))
    print("=" * 80 + "\n")

    return json.dumps(result, ensure_ascii=False, indent=2)


# =========================================================
# 2. 包装成 LlamaIndex Tool
# =========================================================

skill_gateway_tool = FunctionTool.from_defaults(
    run_skill_tool,
    name="skill_tool",
    description=(
        f"""
Unified skill tool. If you are not sure, you can first use the "list_metadata" function of this tool to search for available skills. Then, determine which skill might be the most useful. After that, try to read the SKILL.md file under this skill path to get more detailed information. Finally, based on the content of this file, decide whether to read the documentation in other paths or directly execute the relevant script.

Input format:
{{
  "action": "<action_name>",
  "arg": "<string argument>"
}}

Actions:
- list_metadata: arg = skills root directory (default: {DEFAULT_SKILLS_ROOT})
- read_file:     arg = file path
- run_command:   arg = full command string
"""
    ),
)


# =========================================================
# 3. LLM（Qwen / 百炼 OpenAI-like）
# =========================================================

llm = OpenAILike(
    model="qwen-plus",
    api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    is_chat_model=True,
)


# =========================================================
# 4. 创建 Agent
# =========================================================

agent = ReActAgent(
    tools=[skill_gateway_tool],
    llm=llm,
    verbose=True,
)


# =========================================================
# 5. 运行
# =========================================================

async def main():
    response = await agent.run("我想将 #include <stdio.h>\n\nint main() {\n    puts(\"Generated by agent\");\n    return 0;\n}\n  这段代码转换为ast")# "我想非常深入地了解 AST" #"我想将 #include <stdio.h>\n\nint main() {\n    puts(\"Generated by agent\");\n    return 0;\n}\n  这段代码转换为ast"
    print(response)

asyncio.run(main())
